{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a27ab50",
   "metadata": {},
   "source": [
    "## GRAIN Sample Workflow\n",
    "\n",
    "This notebook creates the GRAIN dataset for a sample OSM data of the country of Egypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f55801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "import joblib\n",
    "import json\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from pyrosm import OSM\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "from shapely.strtree import STRtree\n",
    "from rasterio.sample import sample_gen\n",
    "from core.get_sword_reach_id import get_sword_reach\n",
    "from core.elevation_and_slope import compute_elevDiff_and_slope\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from geopandas.tools import sjoin\n",
    "\n",
    "#feature engineering functions\n",
    "from feature_engineering import vertex_per_length, get_straightness_ratio, mean_turning_angle, get_curvature_index\n",
    "\n",
    "#helper functions\n",
    "from GRAIN_helper_functions import safe_sample, get_koppen_climate_class, add_GRAIN_id, get_osm_name, get_osm_source, get_osm_name_fromOtherTags, get_endpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dece8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to ignore warnings if needed.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34ddca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## File paths for input data\n",
    "\n",
    "egypt_osm_waterways_fp = './GRAIN_sample_data_EGYPT/egypt_waterway.parquet'\n",
    "ml_model_fp = './GRAIN_sample_data_EGYPT/ML_model_random_forest.pkl'\n",
    "sword_data_folder = './GRAIN_sample_data_EGYPT/SWORD_v16_shp/'\n",
    "sword_fileName_format = '{}_sword_reaches_hb{}_v16.shp'\n",
    "hydrobasins_l2_folder = './GRAIN_sample_data_EGYPT/HydroBasins_world_L2'\n",
    "hydrobasin_l6_file = './GRAIN_sample_data_EGYPT/hydrobasins_allBasins_l6_geoParquet_EPSG4326.parquet'\n",
    "hydrobasins_l2_fileName_format = 'hybas_{}_lev02_v1c.shp'\n",
    "world_countries_filePath = './GRAIN_sample_data_EGYPT/world-administrative-boundaries.geojson'\n",
    "\n",
    "sword_continent_map = './GRAIN_sample_data_EGYPT/sword_continents.json'\n",
    "koppen_class_map = './GRAIN_sample_data_EGYPT/koppen_class_label.json'\n",
    "koppen_geiger_fp = './GRAIN_sample_data_EGYPT/koppen_geiger_0p00833333.cog'\n",
    "dem_cog_fp = './GRAIN_sample_data_EGYPT/dem_data/World_e-Atlas-UCSD_SRTM30-plus_v8.cog'\n",
    "\n",
    "esa_cci_cog_path = \"./GRAIN_sample_data_EGYPT/ESACCI-LC-L4-LCCS-Map-300m-P1Y-2015-v2.0.7.cog\" \n",
    "\n",
    "##Output folder path\n",
    "save_path = './GRAIN_sample_data_EGYPT/sample_outputs/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8390fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##function to perform topology based promotion of canal segments\n",
    "def promote_connected_canals_until_convergence(df, buffer_dist=10):\n",
    "    \"\"\"\n",
    "    Repeatedly promotes 'Canal_natural' segments to 'Canal_man_made (connected_round_X)'\n",
    "    if they intersect any currently man-made canal segment.\n",
    "\n",
    "    Parameters:\n",
    "        df : GeoDataFrame with a 'geometry' column and 'predicted_class' field\n",
    "        buffer_dist : distance in meters to consider for intersection (default 10)\n",
    "\n",
    "    Returns:\n",
    "        Updated GeoDataFrame with topologically promoted segments\n",
    "    \"\"\"\n",
    "    round_num = 1\n",
    "    total_promoted = -1  # force first run\n",
    "\n",
    "    while True:\n",
    "        print(f\"â–¶ Topology Promotion Round {round_num}\")\n",
    "\n",
    "        # Get current man-made segments\n",
    "        current_man_made = df[df[\"predicted_class\"].str.startswith(\"Canal_man_made\")].copy()\n",
    "        current_man_made_geoms = list(current_man_made.geometry.values)\n",
    "        tree = STRtree(current_man_made_geoms)\n",
    "\n",
    "        # Get current natural segments to test\n",
    "        to_test = df[df[\"predicted_class\"] == \"Canal_natural\"].copy()\n",
    "        if to_test.empty:\n",
    "            print(\"âœ… No more natural segments left to test. Done.\")\n",
    "            break\n",
    "\n",
    "        promoted_idxs = []\n",
    "\n",
    "        for idx, geom in to_test.geometry.items():\n",
    "            if geom is None or geom.is_empty:\n",
    "                continue\n",
    "            try:\n",
    "                geom_to_check = geom.buffer(buffer_dist) if buffer_dist > 0 else geom\n",
    "                candidate_ids = tree.query(geom_to_check)\n",
    "                candidate_geoms = [current_man_made_geoms[i] for i in candidate_ids]\n",
    "\n",
    "                if any(cand.intersects(geom_to_check) for cand in candidate_geoms):\n",
    "                    promoted_idxs.append(idx)\n",
    "            except Exception as e:\n",
    "                print(f\"[[{idx}]]: Skipping due to error: {e}\")\n",
    "\n",
    "        if not promoted_idxs:\n",
    "            print(\"âœ… No new connections found â€” stopping.\")\n",
    "            break\n",
    "\n",
    "        if round_num==10:\n",
    "            print(\"ðŸ” Maximum rounds reached (10). Stopping promotion.\")\n",
    "            break\n",
    "\n",
    "        label = f\"Canal_man_made (connected_round_{round_num})\"\n",
    "        df.loc[promoted_idxs, \"predicted_class\"] = label\n",
    "        print(f\"ðŸ” Promoted {len(promoted_idxs)} segments to: {label}\")\n",
    "\n",
    "        round_num += 1\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f392466",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to assign canal use based on ESA CCI landcover data\n",
    "def assign_canal_use(grain_data_canals, essa_cci_cog_path):\n",
    "    # print('Entered func')\n",
    "    counter = 0\n",
    "    cropland_class = [10, 11, 12, 20, 30, 130]\n",
    "    urban_andBare_class = [190,200,201,202]\n",
    "    water_class = [210]\n",
    "    grain_data_canals= grain_data_canals.to_crs(epsg=4326)\n",
    "    grain_data_canals['canal_use'] = pd.NA\n",
    "    src = rasterio.open(essa_cci_cog_path) \n",
    "    for idx, row in tqdm(grain_data_canals.iterrows(), total=grain_data_canals.shape[0], desc=\"Processing canal segments\" ):\n",
    "\n",
    "        geom = row.geometry.buffer(.01) #5km buffer\n",
    "        data, _ = mask(src, [geom], crop=True)           # data.shape = (1, h, w)\n",
    "        values  = data[0].ravel()\n",
    "        values  = values[values != src.nodata]\n",
    "\n",
    "        class_counts = np.bincount(values)\n",
    "        idx_sorted = class_counts.argsort()[::-1]\n",
    "        majority_class = idx_sorted[0]\n",
    "        second_major_class = idx_sorted[1] if class_counts[idx_sorted[1]] > 0 else None\n",
    "        # print(row.id, majority_class)\n",
    "        if majority_class in cropland_class:\n",
    "            canal_use_case = \"Agricultural\"\n",
    "            # print(\"Agricultural\")\n",
    "        elif majority_class in urban_andBare_class:\n",
    "            if second_major_class in cropland_class:\n",
    "                canal_use_case = \"Agricultural\"\n",
    "            else:\n",
    "                if majority_class in [200,201,202]:\n",
    "                    canal_use_case = \"Other\"\n",
    "                else:\n",
    "                    canal_use_case = \"Urban Waterway\"\n",
    "            # print(\"Urban\")\n",
    "        elif majority_class in water_class:\n",
    "            if second_major_class in cropland_class:\n",
    "                canal_use_case = \"Agricultural\"\n",
    "            else:\n",
    "                canal_use_case = \"Navigational Waterway\"\n",
    "            # print(\"Navigational\")\n",
    "        else:\n",
    "            if second_major_class in cropland_class:\n",
    "                canal_use_case = \"Agricultural\"\n",
    "            else:\n",
    "                canal_use_case = \"Other\"\n",
    "            # print(\"Natural\")\n",
    "        # print(majority_class,second_major_class,canal_use_case)\n",
    "        # print(canal_use_case)\n",
    "        grain_data_canals.at[idx, \"canal_use\"] = canal_use_case\n",
    "        counter += 1\n",
    "        \n",
    "    print('âœ” Completed processing {} canal segments'.format(counter))\n",
    "    return grain_data_canals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4855e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## primary function to run the GRAIN ML model\n",
    "def run_grain_ml_model(country):\n",
    "    feature_cols = ['elev_diff','straightness_ratio','curvature_index_per_100m','mean_turning_angle','slope']\n",
    "\n",
    "    country_osm_waterways_data_fp = egypt_osm_waterways_fp\n",
    "    country_osm_waterways_data = gpd.read_parquet(country_osm_waterways_data_fp)\n",
    "    country_osm_waterways_data = country_osm_waterways_data[country_osm_waterways_data['geometry'].geom_type.isin(['LineString', 'MultiLineString'])]\n",
    "\n",
    "    country_osm_waterways_data = country_osm_waterways_data.to_crs(epsg=3857)\n",
    "    if \"osm_id\" in country_osm_waterways_data.columns:\n",
    "        country_osm_waterways_data.rename(columns={\"osm_id\": \"id\"}, inplace=True)\n",
    "        \n",
    "    if \"waterway\"  in country_osm_waterways_data.columns:\n",
    "            country_osm_waterways_data = country_osm_waterways_data.rename(columns={\"waterway\": \"osm_label\"})\n",
    "\n",
    "    if \"tags\" in country_osm_waterways_data.columns:\n",
    "        columns_to_keep = [\"id\", \"geometry\", \"osm_label\", \"tags\"]\n",
    "    elif \"other_tags\" in country_osm_waterways_data.columns:\n",
    "        columns_to_keep = [\"id\", \"geometry\", \"osm_label\", \"other_tags\"]\n",
    "    else:\n",
    "        columns_to_keep = [\"id\", \"geometry\", \"osm_label\"]\n",
    "    if \"name\" in country_osm_waterways_data.columns:\n",
    "        columns_to_keep.append(\"name\")\n",
    "\n",
    "    country_osm_canals = country_osm_waterways_data[country_osm_waterways_data['osm_label'].isin(['canal', 'ditch', 'drain'])]\n",
    "    country_osm_rivers = country_osm_waterways_data[country_osm_waterways_data['osm_label'].isin(['river', 'stream'])]\n",
    "    country_osm_rivers = country_osm_rivers[columns_to_keep]\n",
    "    country_osm_canals = country_osm_canals[columns_to_keep]\n",
    "\n",
    "    #computing features\n",
    "    print(f'[{country}]: Computing features. This might take a while...')\n",
    "    print(f'[{country}]: Rivers')\n",
    "\n",
    "    country_osm_rivers[\"straightness_ratio\"] = country_osm_rivers.geometry.apply(get_straightness_ratio)\n",
    "    country_osm_rivers[\"mean_turning_angle\"] = country_osm_rivers.geometry.apply(mean_turning_angle)\n",
    "    country_osm_rivers[\"curvature_index_per_100m\"] = country_osm_rivers.geometry.apply(get_curvature_index)\n",
    "    #compute length of the geometry in km\n",
    "    country_osm_rivers['length'] = country_osm_rivers['geometry'].length / 1E3\n",
    "    country_osm_rivers = compute_elevDiff_and_slope(dem_cog_fp,country_osm_rivers)\n",
    "\n",
    "\n",
    "    # do the same for canal\n",
    "    print(f'[{country}]: Canals')\n",
    "    country_osm_canals[\"straightness_ratio\"] = country_osm_canals.geometry.apply(get_straightness_ratio)\n",
    "    country_osm_canals[\"mean_turning_angle\"] = country_osm_canals.geometry.apply(mean_turning_angle)\n",
    "    country_osm_canals[\"curvature_index_per_100m\"] = country_osm_canals.geometry.apply(get_curvature_index)\n",
    "    #compute length of the geometry in km\n",
    "    country_osm_canals['length'] = country_osm_canals['geometry'].length / 1E3\n",
    "    country_osm_canals = compute_elevDiff_and_slope(dem_cog_fp,country_osm_canals)\n",
    "\n",
    "    #drop nans\n",
    "    cols_checkforNans = ['elev_diff', 'slope', 'straightness_ratio', 'mean_turning_angle', 'curvature_index_per_100m']\n",
    "    country_osm_rivers_clean = country_osm_rivers.dropna(subset=cols_checkforNans).copy()\n",
    "    country_osm_canals_clean = country_osm_canals.dropna(subset=cols_checkforNans).copy()\n",
    "\n",
    "    #loading random forest model\n",
    "    model_fp = ml_model_fp\n",
    "    model = joblib.load(model_fp)\n",
    "\n",
    "\n",
    "    X_country_osm_rivers = country_osm_rivers_clean[feature_cols]\n",
    "\n",
    "    #predict using random forest model\n",
    "    country_osm_rivers_clean[\"predicted_label\"] = model.predict(X_country_osm_rivers)\n",
    "    country_osm_rivers_clean[\"predicted_class\"] = country_osm_rivers_clean[\"predicted_label\"].map({0: \"river\", 1: \"canal\"})\n",
    "    #getting confidence\n",
    "    proba_rivers = model.predict_proba(X_country_osm_rivers)   \n",
    "    country_osm_rivers_clean[[\"prob_river\", \"prob_canal\"]] = proba_rivers\n",
    "\n",
    "    X_country_osm_canals = country_osm_canals_clean[feature_cols]\n",
    "    #predict using random forest model\n",
    "    country_osm_canals_clean[\"predicted_label\"] = model.predict(X_country_osm_canals)\n",
    "    country_osm_canals_clean[\"predicted_class\"] = country_osm_canals_clean[\"predicted_label\"].map({0: \"river\", 1: \"canal\"})\n",
    "    proba_canals = model.predict_proba(X_country_osm_canals)   \n",
    "    country_osm_canals_clean[[\"prob_river\", \"prob_canal\"]] = proba_canals\n",
    "\n",
    "\n",
    "    ##adding name, osm source, and alt name fields\n",
    "    #rivers\n",
    "    if \"name\" in country_osm_rivers_clean.columns:\n",
    "        country_osm_rivers_clean = country_osm_rivers_clean.rename(columns={\"name\": \"osm_name\"})\n",
    "    if \"tags\" in country_osm_rivers_clean.columns:\n",
    "        if \"osm_name\" not in country_osm_rivers_clean.columns:\n",
    "            country_osm_rivers_clean['osm_name'] = country_osm_rivers_clean['tags'].apply(get_osm_name)\n",
    "        country_osm_rivers_clean['osm_source'] = country_osm_rivers_clean['tags'].apply(get_osm_source) \n",
    "\n",
    "    if \"other_tags\" in country_osm_rivers_clean.columns:\n",
    "        if \"osm_name\" not in country_osm_rivers_clean.columns:\n",
    "            country_osm_rivers_clean['osm_name'] = country_osm_rivers_clean['other_tags'].apply(get_osm_name_fromOtherTags)\n",
    "        else:\n",
    "            country_osm_rivers_clean['alt_name'] = country_osm_rivers_clean['other_tags'].apply(get_osm_name_fromOtherTags)\n",
    "\n",
    "    if \"osm_source\" not in country_osm_rivers_clean.columns:\n",
    "        country_osm_rivers_clean['osm_source'] = None\n",
    "\n",
    "    if \"alt_name\" not in country_osm_rivers_clean.columns:\n",
    "        country_osm_rivers_clean['alt_name'] = None\n",
    "    #canals\n",
    "    if \"name\" in country_osm_canals_clean.columns:\n",
    "        country_osm_canals_clean = country_osm_canals_clean.rename(columns={\"name\": \"osm_name\"})\n",
    "    if \"tags\" in country_osm_canals_clean.columns:\n",
    "        if \"osm_name\" not in country_osm_canals_clean.columns:\n",
    "            country_osm_canals_clean['osm_name'] = country_osm_canals_clean['tags'].apply(get_osm_name)\n",
    "        country_osm_canals_clean['osm_source'] = country_osm_canals_clean['tags'].apply(get_osm_source) \n",
    "\n",
    "    if \"other_tags\" in country_osm_canals_clean.columns:\n",
    "        if \"osm_name\" not in country_osm_canals_clean.columns:\n",
    "            country_osm_canals_clean['osm_name'] = country_osm_canals_clean['other_tags'].apply(get_osm_name_fromOtherTags)\n",
    "        else:\n",
    "            country_osm_canals_clean['alt_name'] = country_osm_canals_clean['other_tags'].apply(get_osm_name_fromOtherTags)\n",
    "\n",
    "    if \"osm_source\" not in country_osm_canals_clean.columns:\n",
    "        country_osm_canals_clean['osm_source'] = None\n",
    "\n",
    "    if \"alt_name\" not in country_osm_canals_clean.columns:\n",
    "        country_osm_canals_clean['alt_name'] = None\n",
    "\n",
    "\n",
    "    #removing any sword rivers from canals\n",
    "\n",
    "    sword_continent_map_data = json.load(open(sword_continent_map))\n",
    "    random_canal = country_osm_canals_clean.sample(n=1, random_state=21)\n",
    "    country_iso, country_name_official, continent_name, sword_reach_id = get_sword_reach(random_canal)\n",
    "\n",
    "    sword_gdfs = []\n",
    "    print(f'[[{country}]]:Removing any sword rivers from canal dataset')\n",
    "    for sword_id in sword_reach_id:\n",
    "\n",
    "        for key, value in sword_continent_map_data.items():\n",
    "            if str(sword_id) in value:\n",
    "                continent_abbrv = key\n",
    "\n",
    "        sword_file_path = os.path.join(sword_data_folder,continent_abbrv,sword_fileName_format.format(continent_abbrv.lower(), sword_id))\n",
    "\n",
    "        sword_data_gpd = gpd.read_file(sword_file_path)\n",
    "        sword_gdfs.append(sword_data_gpd)\n",
    "\n",
    "    sword_data_gpd = pd.concat(sword_gdfs)\n",
    "    country_sword_mercator = sword_data_gpd.to_crs(epsg=3857)\n",
    "\n",
    "    country_osm_canals_clean = country_osm_canals_clean.to_crs(epsg=3857)\n",
    "    country_osm_canals_sword_intersection = gpd.sjoin(country_osm_canals_clean, country_sword_mercator, how=\"inner\", predicate=\"intersects\")\n",
    "    to_remove_index = country_osm_canals_sword_intersection.index\n",
    "    country_osm_canals_final = country_osm_canals_clean.drop(index=to_remove_index)\n",
    "\n",
    "    print(f'[[{country}]]:Running checks for any osm canals labeled as rivers')\n",
    "    country_osm_rivers_clean = country_osm_rivers_clean.to_crs(epsg=3857)\n",
    "    country_osm_rivers_toCheckForNamedCanals = country_osm_rivers_clean.copy()\n",
    "    cols = [\"osm_name\", \"alt_name\"]\n",
    "    CANAL_RE = r\"\\bcanal\\b\" \n",
    "\n",
    "    mask_namedCanals = (\n",
    "        country_osm_rivers_toCheckForNamedCanals[cols]\n",
    "        .apply(lambda s: s.str.contains(CANAL_RE, case=False, na=False))\n",
    "        .any(axis=1)                         \n",
    "    )\n",
    "    canals_to_merge = country_osm_rivers_toCheckForNamedCanals[mask_namedCanals]\n",
    "    canals_to_merge['predicted_class'] = 'canal'\n",
    "    print(\"Identified\", len(canals_to_merge), \"river segments that have tag 'canal' in its name. Merging with canals\")\n",
    "    country_osm_canals_final = pd.concat([country_osm_canals_clean, canals_to_merge], ignore_index=True)\n",
    "\n",
    "    print(f'[[{country}]]:Relabeling canals classified as rivers if they are connected to canals endpoints')\n",
    "    ml_canals_man_made = country_osm_canals_final[country_osm_canals_final[\"predicted_class\"] == \"canal\"].copy()\n",
    "    ml_canals_rivers = country_osm_canals_final[country_osm_canals_final[\"predicted_class\"] == \"river\"].copy()\n",
    "\n",
    "    # Collect all endpoints\n",
    "    man_made_endpoints = []\n",
    "    for geom in ml_canals_man_made.geometry:\n",
    "        start, end = get_endpoints(geom)\n",
    "        man_made_endpoints.extend([start, end])\n",
    "\n",
    "    # Create a spatial index for fast lookup\n",
    "    endpoint_tree = STRtree(man_made_endpoints)\n",
    "    man_made_geoms = list(ml_canals_man_made.geometry)\n",
    "    man_made_tree = STRtree(man_made_geoms)\n",
    "    #checking if the endpoints of canals classified as rivers are within a buffer distance of man-made canals. if so they are man-made canals\n",
    "    buffer_dist = 50  # in meters\n",
    "\n",
    "    promoted_idxs = []\n",
    "\n",
    "    for idx, geom in ml_canals_rivers.geometry.items():\n",
    "            if geom is None or geom.is_empty:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Buffer canal geom slightly to catch near-touches (optional)\n",
    "                geom_to_check = geom.buffer(buffer_dist) if buffer_dist > 0 else geom\n",
    "                \n",
    "                # Query STRtree for potential matches\n",
    "                candidates_id = man_made_tree.query(geom_to_check)\n",
    "                # Check if any intersect\n",
    "                #if candidates in not empty break out of loop\n",
    "                if len(candidates_id) > 0:\n",
    "                    candidate_geoms = [man_made_geoms[i] for i in candidates_id]\n",
    "                    if any(candidate.intersects(geom_to_check) for candidate in candidate_geoms):\n",
    "                        promoted_idxs.append(idx)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"[[{idx}]]: Skipping due to error: {e}\")\n",
    "                traceback.print_exc()\n",
    "    print(f'Identified {len(promoted_idxs)} segments. Promoting...')\n",
    "\n",
    "    ml_canals_rivers.loc[promoted_idxs, \"predicted_class\"] = \"Canal_man_made (connected)\"\n",
    "    ml_canals_rivers.loc[~ml_canals_rivers.index.isin(promoted_idxs), \"predicted_class\"] = \"Canal_natural\"\n",
    "\n",
    "    #combining back\n",
    "    ml_canals_cleaned = pd.concat([ml_canals_man_made, ml_canals_rivers], ignore_index=True)\n",
    "\n",
    "    print(f'[[{country}]]:Using successive topology checks to promote canal regments labelled as canal_natural')\n",
    "    ml_canals_cleaned = promote_connected_canals_until_convergence(ml_canals_cleaned, buffer_dist=50)\n",
    "\n",
    "    print(\"Adding osm rivers classified as canals to river dataset based on intersection criteria\")\n",
    "    ml_canals_cleaned_preRiver = ml_canals_cleaned.copy()\n",
    "    ml_canals_cleaned_preRiver.loc[~ml_canals_cleaned_preRiver[\"predicted_class\"].isin([\"canal\", \"Canal_natural\"]), \"predicted_class\"] = \"canal\"\n",
    "\n",
    "    country_rivers_classified_man_made_canals = country_osm_rivers_clean[country_osm_rivers_clean[\"predicted_class\"] == \"canal\"]\n",
    "    river_man_made = country_rivers_classified_man_made_canals.copy()\n",
    "\n",
    "    canal_geoms = list(ml_canals_cleaned_preRiver.geometry.values)\n",
    "    canal_tree = STRtree(canal_geoms)\n",
    "\n",
    "    intersecting_river_idxs = []\n",
    "\n",
    "    joined = sjoin(river_man_made, ml_canals_cleaned_preRiver, how=\"left\", predicate=\"intersects\")\n",
    "    intersecting_idxs = joined[~joined.index_right.isna()].index\n",
    "    river_man_made.loc[intersecting_idxs, \"predicted_class\"] = \"Canal_man_made_connected\"\n",
    "\n",
    "    final_canal_dataset = pd.concat(\n",
    "            [ml_canals_cleaned_preRiver, river_man_made[river_man_made[\"predicted_class\"] == \"Canal_man_made_connected\"]],\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "    final_canal_dataset.loc[final_canal_dataset['predicted_class']=='Canal_man_made_connected', 'predicted_class'] = 'canal'\n",
    "\n",
    "    print(f\"[[{country}]]:Running checks for any osm canals. Removes those that have 'River' in their OSM names\")\n",
    "    final_canal_dataset = final_canal_dataset.to_crs(epsg=3857)\n",
    "    final_canal_dataset_toCheckForNamedRivers = final_canal_dataset.copy()\n",
    "    cols = [\"osm_name\", \"alt_name\"]\n",
    "    RIVER_RE = r\"\\briver\\b\" \n",
    "    CANAL_RE = r\"\\bcanal\\b\"\n",
    "    mask_namedRivers = (\n",
    "        final_canal_dataset_toCheckForNamedRivers[cols]\n",
    "        .apply(lambda s: s.str.contains(RIVER_RE, case=False, na=False))\n",
    "        .any(axis=1)                         \n",
    "    )\n",
    "    mask_namedCanals = (\n",
    "        final_canal_dataset_toCheckForNamedRivers[cols]\n",
    "        .apply(lambda s: s.str.contains(CANAL_RE, case=False, na=False))\n",
    "        .any(axis=1)\n",
    "    )\n",
    "    mask_to_drop = mask_namedRivers & ~mask_namedCanals\n",
    "\n",
    "    final_canal_dataset_clean = final_canal_dataset_toCheckForNamedRivers.loc[~mask_to_drop].copy()\n",
    "    #Assigning Canal use case based on ES CCI LULC Dataset 2015\n",
    "\n",
    "    print(f'[[{country}]]: Assigning canal use case based on ESA CCI LULC data')\n",
    "    final_canal_dataset_withUseCase = assign_canal_use(final_canal_dataset_clean, esa_cci_cog_path)\n",
    "    print(f'[[{country}]]: Adding GRAIN ID in the format ISO3-code_PFAF Level 6 ID_sequential numbering')\n",
    "    final_canal_dataset_withGrainID = add_GRAIN_id(final_canal_dataset_withUseCase, country_iso[0], hydrobasin_l6_file)\n",
    "    print(f'[[{country}]]: Adding country and continent names and Koppen Climate Class')\n",
    "    final_canal_dataset_withGrainID['country'] = country_name_official[0]\n",
    "    final_canal_dataset_withGrainID['continent'] = continent_name[0]\n",
    "    final_canal_dataset_withGrainID['country_iso'] = country_iso[0]\n",
    "    final_canal_dataset_withGrainID['update_date'] = \"2025-07-31\"\n",
    "    final_canal_dataset_withGrainID['version'] = \"v.1.0.0\"\n",
    "    final_canal_dataset_withKoppenClass = get_koppen_climate_class(final_canal_dataset_withGrainID,koppen_class_map, koppen_geiger_fp )\n",
    "    print(f'[[{country}]]: Trimming and renaming columns')\n",
    "    columns_to_keep = [\"grain_id\", \"id\", \"country\", \"continent\", \"country_iso\", \"length\",\"elev_diff\",\"slope\",\"predicted_class\",\"prob_canal\",\n",
    "    \"osm_name\",\"osm_label\", \"tags\",\"osm_source\", \"alt_name\", \"canal_use\",\"koppen_class_code\", \"update_date\",\"version\", \"geometry\"]\n",
    "    if \"tags\" not in final_canal_dataset_withKoppenClass.columns:\n",
    "        final_canal_dataset_withKoppenClass[\"tags\"] = None\n",
    "\n",
    "    final_grain_canal_dataset = final_canal_dataset_withKoppenClass[columns_to_keep]\n",
    "    final_grain_canal_dataset = final_grain_canal_dataset.rename(columns={\"id\": \"osm_id\", \"slope\": \"slope_MKM\",\n",
    "    \"length\": \"length_KM\", \"elev_diff\": \"elev_diff_M\", \"prob_canal\": \"confidence\", })\n",
    "\n",
    "    print(f'[[{country}]]:Saving final dataset for {country} to parquet and geojson file')\n",
    "    final_grain_canal_dataset.to_parquet(f\"{save_path}/{country}_GRAIN_v.1.0.parquet\")\n",
    "    final_grain_canal_dataset.to_file(f\"{save_path}/{country}_GRAIN_v.1.0.shp\", driver='ESRI Shapefile')\n",
    "    print(f'[[{country}]]:Completed')\n",
    "    print('==========================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d71e407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Egypt]: Computing features. This might take a while...\n",
      "[Egypt]: Rivers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing slopes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4645/4645 [00:01<00:00, 2342.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors in slope computation: 0\n",
      "[Egypt]: Canals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing slopes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18632/18632 [00:07<00:00, 2606.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors in slope computation: 0\n",
      "Country detected: ['Egypt'] ISO: ['EGY']\n",
      "Number of level 2 hydrobasins in Egypt: 5\n",
      "PFAF_IDs: [11, 15, 17, 21, 29]\n",
      "returning pfaf ids as sword reach ids\n",
      "[[Egypt]]:Removing any sword rivers from canal dataset\n",
      "[[Egypt]]:Running checks for any osm canals labeled as rivers\n",
      "Identified 0 river segments that have tag 'canal' in its name. Merging with canals\n",
      "[[Egypt]]:Relabeling canals classified as rivers if they are connected to canals endpoints\n",
      "Identified 64 segments. Promoting...\n",
      "[[Egypt]]:Using successive topology checks to promote canal regments labelled as canal_natural\n",
      "â–¶ Topology Promotion Round 1\n",
      "âœ… No new connections found â€” stopping.\n",
      "Adding osm rivers classified as canals to river dataset based on intersection criteria\n",
      "[[Egypt]]:Running checks for any osm canals. Removes those that have 'River' in their OSM names\n",
      "[[Egypt]]: Assigning canal use case based on ESA CCI LULC data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing canal segments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18769/18769 [00:21<00:00, 879.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Completed processing 18769 canal segments\n",
      "[[Egypt]]: Adding GRAIN ID in the format ISO3-code_PFAF Level 6 ID_sequential numbering\n",
      "EGY\n",
      "[[Egypt]]: Adding country and continent names and Koppen Climate Class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Koppen Climate Class: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19050/19050 [00:08<00:00, 2338.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Egypt]]: Trimming and renaming columns\n",
      "[[Egypt]]:Saving final dataset for Egypt to parquet and geojson file\n",
      "[[Egypt]]:Completed\n",
      "==========================================================================\n",
      "[[Egypt]]:Completed\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "## Running grain for sample region of Egypt\n",
    "try:\n",
    "    run_grain_ml_model('Egypt')\n",
    "except Exception as e:\n",
    "    print(f\"Error running GRAIN ML model: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25d65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".grain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
